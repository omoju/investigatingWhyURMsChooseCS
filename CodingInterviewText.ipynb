{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import DataFrame\n",
    "import nltk\n",
    "\n",
    "df = pd.read_csv('Data/InterviewDataResponses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns =  [\n",
    "'timestamp','howLearnComp',\n",
    "'negAspectComp','dataLab','magicWand','csCourseFuture','currFactor','changeThoughtBerkeley','changePerceptnCS',\n",
    "'funAspectClass','unfunAspectClass','respectCourseStaff','courseCulture61A','changeThoughtBerkeley2',\n",
    "'moreCSClasses','perceptStudyCSChange','feelMinorityCS','whatFirstBroughtCourseAttention','reservationTakingClass',\n",
    "'probStudyCS','relationshipProgrammerScientist','comptThink','enjoyCourse','enjoyProbSolv',\n",
    "'priorCSbeforeClass','academicStrenghts','otherAcademicInterest','majorBerkeley','answerDiff','strengthCS',\n",
    "'coolestAspectCS','thinkSomeOneCSDo','benefitStudyCS','theName','gender','priorExposureToCS','cs10','cs61A',\n",
    "'race','acadClass','experienceSnap','anythingLikeToShare','extra','expectGetOutOfCourse',\n",
    "'q_CT','q2','q3','q4','q5','q6','q7','q8','q9','q10','q11','q12','q13','q14','q15','q16','q17']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs10 = df[df.cs10 == 'yes']\n",
    "cs61a = df[df.cs61A == 'yes']\n",
    "cs10.reset_index(drop=True)\n",
    "cs61a.reset_index(drop=True)\n",
    "\n",
    "cs10_female = cs10[cs10.gender == 'female' ]\n",
    "cs10_male = cs10[cs10.gender == 'male']\n",
    "cs10_female = cs10_female.reset_index(drop=True)\n",
    "cs10_male = cs10_male.reset_index(drop=True)\n",
    "\n",
    "\n",
    "cs61a_female = cs61a[cs61a.gender == 'female']\n",
    "cs61a_female = cs61a_female[pd.isnull(cs61a_female.cs10)]\n",
    "\n",
    "cs61a_male = cs61a[cs61a.gender == 'male']\n",
    "cs61a_male = cs61a_male[pd.isnull(cs61a_male.cs10)]\n",
    "cs61a_female = cs61a_female.reset_index(drop=True)\n",
    "cs61a_male = cs61a_male.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "def leaves(tree):\n",
    "    \"\"\"Finds NP (nounphrase) leaf nodes of a chunk tree.\"\"\"\n",
    "    for subtree in tree.subtrees(filter = lambda t: t.node=='NP'):\n",
    "        yield subtree.leaves()\n",
    "\n",
    "def normalise(word):\n",
    "    \"\"\"Normalises words to lowercase and stems and lemmatizes it.\"\"\"\n",
    "    word = word.lower()\n",
    "    #word = stemmer.stem_word(word)\n",
    "    word = lemmatizer.lemmatize(word)\n",
    "    return word\n",
    "\n",
    "def acceptable_word(word):\n",
    "    \"\"\"Checks conditions for acceptable word: length, stopword.\"\"\"\n",
    "    accepted = bool(2 <= len(word) <= 40\n",
    "        and word.lower() not in stopwords)\n",
    "    return accepted\n",
    "\n",
    "\n",
    "def get_terms(tree):\n",
    "    for leaf in leaves(tree):\n",
    "        term = [ normalise(w) for w,t in leaf if acceptable_word(w) ]\n",
    "        yield term\n",
    "\n",
    "        # Used when tokenizing words\n",
    "sentence_re = r'''(?x)      # set flag to allow verbose regexps\n",
    "      ([A-Z])(\\.[A-Z])+\\.?  # abbreviations, e.g. U.S.A.\n",
    "    | \\w+(-\\w+)*            # words with optional internal hyphens\n",
    "    | \\$?\\d+(\\.\\d+)?%?      # currency and percentages, e.g. $12.40, 82%\n",
    "    | \\.\\.\\.                # ellipsis\n",
    "    | [][.,;\"'?():-_`]      # these are separate tokens\n",
    "'''\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "#Taken from Su Nam Kim Paper...\n",
    "grammar = r\"\"\"\n",
    "    NBAR:\n",
    "        {<NN.*|JJ>*<NN.*>}  # Nouns and Adjectives, terminated with Nouns\n",
    "        \n",
    "    NP:\n",
    "        {<NBAR>}\n",
    "        {<NBAR><IN><NBAR>}  # Above, connected with in/of/etc...\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def iterateCodes(dfName, category, item):\n",
    "    \n",
    "    \n",
    "        dfCol = []\n",
    "        dfCol.append(dfName+category+'.columns')\n",
    "        \n",
    "        code_tmp = {}\n",
    "        \n",
    "        dfItem = []\n",
    "        dfItem.append(dfName+category+'.iterrows()')\n",
    "        for row, columns in eval(dfItem[0]):\n",
    "            if pd.isnull(columns[item]):\n",
    "                continue\n",
    "            else:\n",
    "                text = str(columns[item]).split()\n",
    "                text = ' '.join(text)\n",
    "                chunker = nltk.RegexpParser(grammar)\n",
    "                toks = nltk.regexp_tokenize(text, sentence_re)\n",
    "                postoks = nltk.tag.pos_tag(toks)\n",
    "                tree = chunker.parse(postoks)\n",
    "                terms = get_terms(tree)\n",
    "                    \n",
    "                code = []\n",
    "                for term in terms:\n",
    "                    for word in term: \n",
    "                        if code_tmp.has_key(word):\n",
    "                            code_tmp[word] += 1\n",
    "                        else:\n",
    "                            code_tmp[word] = 0 \n",
    "                    \n",
    "        return code_tmp\n",
    "    \n",
    "\n",
    "def printCode(coding):\n",
    "    \n",
    "    window = 10\n",
    "\n",
    "    for key in sorted(coding):\n",
    "        if coding[key] > 1 and (window > 0 and window <=10):\n",
    "            print \"%s\" % (key),\n",
    "            window = window - 1\n",
    "        elif window < 1:\n",
    "            print '\\n'\n",
    "            window = 10\n",
    "    print '\\n------ E N D-------\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "items = cs10.columns.values\n",
    "for item in items:\n",
    "    coding = {}\n",
    "    coding = iterateCodes('cs10', '', item)\n",
    "    print item, \"CS10\\n\"\n",
    "    printCode(coding)\n",
    "\n",
    "    coding = iterateCodes('cs61a', '', item)\n",
    "    print item, \"CS61A\\n\"\n",
    "    printCode(coding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
